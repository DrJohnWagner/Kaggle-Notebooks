{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-02-14T09:26:15.635267Z","iopub.status.busy":"2022-02-14T09:26:15.634691Z","iopub.status.idle":"2022-02-14T09:26:15.648810Z","shell.execute_reply":"2022-02-14T09:26:15.647526Z","shell.execute_reply.started":"2022-02-14T09:26:15.635215Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","import random\n","import numpy as np\n","from pprint import pprint\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.data import Dataset\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.callbacks import LambdaCallback\n","# from tensorflow.keras.callbacks import ReduceLROnPlateau\n","# from tensorflow.keras.callbacks import EarlyStopping\n","# from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import InputLayer\n","from tensorflow.keras.layers import MaxPool2D\n","from tensorflow.keras.layers import Resizing\n","from tensorflow.keras.layers import Rescaling\n","# from tensorflow.keras.models import load_model\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","\n","import plotly.graph_objs as go\n","from plotly.subplots import make_subplots\n","\n","try:\n","    from PDSUtilities.tensorflow.tvp_split import tvp_split\n","    from PDSUtilities.tensorflow.plot_history import plot_history\n","    from PDSUtilities.plotly.create_image_subplots import create_image_subplots\n","    import PDSUtilities.plotly.templates\n","except ImportError as e:\n","    try:\n","        %pip install PDSUtilities --upgrade\n","        from PDSUtilities.tensorflow.tvp_split import tvp_split\n","        from PDSUtilities.tensorflow.plot_history import plot_history\n","        from PDSUtilities.plotly.create_image_subplots import create_image_subplots\n","        import PDSUtilities.plotly.templates\n","    except ImportError as e:\n","        raise ImportError(\"You must install PDSUtilities to plot importance and trees...\") from e\n","\n","from ipywidgets import HBox\n","\n","# from utilities import read_or_create_csv\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n","print(\"Devices: \", tf.config.list_physical_devices(\"GPU\"))\n","\n","LABELS_COLUMN = \"Label\"\n","FILENAMES_COLUMN = \"Filename\"\n","\n","BATCH_SIZE = 128\n","IMAGE_HEIGHT = 64\n","IMAGE_WIDTH = 64\n","CHANNELS = 3\n","\n","FILTERS = 32\n","KERNEL = 5\n","STRIDES = 2\n","ACTIVATION = \"relu\"\n","DROPOUT = 0.5\n","DENSE = 256\n","CLASSES = 29\n","LEARNING_RATE = 0.001\n","\n","ROOT_DIR = \"/kaggle/input/asl-alphabet\"\n","ROOT_DIR = \"../archive\"\n","TRAINING_DIR = os.path.join(ROOT_DIR, \"asl_alphabet_train/asl_alphabet_train\")\n","TESTING_DIR = os.path.join(ROOT_DIR, \"asl_alphabet_test/asl_alphabet_test\")\n","# /kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/*_test.jpg\n","# /kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/?/?#.jpg\n","# \n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         if \"_test\" in dirname:\n","#             print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-14T07:44:15.471218Z","iopub.status.busy":"2022-02-14T07:44:15.469761Z","iopub.status.idle":"2022-02-14T07:44:15.847656Z","shell.execute_reply":"2022-02-14T07:44:15.846928Z","shell.execute_reply.started":"2022-02-14T07:44:15.471171Z"},"trusted":true},"outputs":[],"source":["labels = [label for label in os.listdir(TRAINING_DIR)]\n","df = pd.DataFrame([\n","    {\n","        LABELS_COLUMN: label,\n","        FILENAMES_COLUMN: os.path.join(TRAINING_DIR, label, filename)\n","    }\n","    for label in labels\n","    for filename in os.listdir(os.path.join(TRAINING_DIR, label))\n","])\n","df = df.sample(frac=1).reset_index(drop=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-14T07:45:53.797927Z","iopub.status.busy":"2022-02-14T07:45:53.797607Z","iopub.status.idle":"2022-02-14T07:45:53.833735Z","shell.execute_reply":"2022-02-14T07:45:53.833037Z","shell.execute_reply.started":"2022-02-14T07:45:53.797892Z"},"trusted":true},"outputs":[],"source":["dt, dv, dp = tvp_split(df, 0.2, 0.1)\n","print(f\"Length of training images list: {len(dt)}.\")\n","print(f\"Length of validation images list: {len(dv)}.\")\n","print(f\"Length of prediction images list: {len(dp)}.\")\n","print(f\"Number of unique labels in training images list: {len(dt[LABELS_COLUMN].unique())}.\")\n","print(f\"Number of unique labels in validation images list: {len(dv[LABELS_COLUMN].unique())}.\")\n","print(f\"Number of unique labels in prediction images list: {len(dp[LABELS_COLUMN].unique())}.\")\n","# Insert plot here showing distributions of labels across the three sets..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-14T08:06:42.944809Z","iopub.status.busy":"2022-02-14T08:06:42.944461Z","iopub.status.idle":"2022-02-14T08:07:24.355045Z","shell.execute_reply":"2022-02-14T08:07:24.35361Z","shell.execute_reply.started":"2022-02-14T08:06:42.944772Z"},"trusted":true},"outputs":[],"source":["# Do not scale images here...do that in a network layer...\n","xyt = ImageDataGenerator().flow_from_dataframe(dt, x_col=FILENAMES_COLUMN, y_col=LABELS_COLUMN,\n","    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), class_mode='categorical', batch_size=BATCH_SIZE\n",")\n","xyv = ImageDataGenerator().flow_from_dataframe(dv, x_col=FILENAMES_COLUMN, y_col=LABELS_COLUMN,\n","    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), class_mode='categorical', batch_size=BATCH_SIZE,\n","    shuffle=False\n",")\n","xyp = ImageDataGenerator().flow_from_dataframe(dp, x_col=FILENAMES_COLUMN, y_col=LABELS_COLUMN,\n","    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), class_mode='categorical', batch_size=BATCH_SIZE,\n","    shuffle=False\n",")\n","\n","x, y = next(xyt)\n","class_labels = list(xyt.class_indices.keys())\n","class_labels = [\"Label: \" + class_labels[c] for c in np.argmax(y[0:16], axis=-1)]\n","fig = create_image_subplots(x[:16], labels=class_labels, width=720, height=800)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# MaxAbsPool2D\n","import tensorflow as tf\n","\n","class MaxAbsPool2D(tf.keras.layers.Layer):\n","    def __init__(self, pool_size, pad_to_fit=False):\n","        super(MaxAbsPool2D, self).__init__()\n","        self.pad = pad_to_fit\n","        self.pool_size = pool_size\n","\n","    def compute_output_shape(self, in_shape):\n","        if self.pad:\n","            return (in_shape[0],\n","                    tf.math.ceil(in_shape[1] / self.pool_size),\n","                    tf.math.ceil(in_shape[2] / self.pool_size),\n","                    in_shape[3])\n","        return (in_shape[0],\n","                (in_shape[1] // self.pool_size),\n","                (in_shape[2] // self.pool_size),\n","                in_shape[3])\n","\n","    def compute_padding(self, in_shape):\n","        mod_y = in_shape[1] % self.pool_size\n","        y1 = mod_y // 2\n","        y2 = mod_y - y1\n","        mod_x = in_shape[2] % self.pool_size\n","        x1 = mod_x // 2\n","        x2 = mod_x - x1\n","        self.padding = ((0, 0), (y1, y2), (x1, x2), (0, 0))\n","\n","    def build(self, input_shape):\n","        self.in_shape = input_shape\n","        self.out_shape = self.compute_output_shape(self.in_shape)\n","        self.compute_padding(self.in_shape)\n","\n","    def stack(self, inputs):\n","        if self.pad:\n","            inputs = tf.pad(inputs, self.padding)\n","        max_height = (tf.shape(inputs)[1] // self.pool_size) * self.pool_size\n","        max_width = (tf.shape(inputs)[2] // self.pool_size) * self.pool_size\n","        stack = tf.stack(\n","            [inputs[:, i:max_height:self.pool_size, j:max_width:self.pool_size, :]\n","             for i in range(self.pool_size) for j in range(self.pool_size)],\n","            axis=-1)\n","        return stack\n","\n","    @tf.function\n","    def call(self, inputs, training=None):\n","        stacked = self.stack(inputs)\n","        inds = tf.argmax(tf.abs(stacked), axis=-1, output_type=tf.int32)\n","        ks = tf.shape(stacked)\n","        idx = tf.stack([\n","            *tf.meshgrid(\n","                tf.range(0, ks[0]),\n","                tf.range(0, ks[1]),\n","                tf.range(0, ks[2]),\n","                tf.range(0, ks[3]),\n","                indexing='ij'\n","            ), inds],\n","            axis=-1)\n","        x = tf.gather_nd(stacked, idx)\n","        x = tf.reshape(x, (-1, *self.out_shape[1:]))\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CosSim2D\n","import math\n","\n","import tensorflow as tf\n","\n","class CosSim2D(tf.keras.layers.Layer):\n","    def __init__(self, kernel_size, units=32, stride=1, padding='valid'):\n","        super(CosSim2D, self).__init__()\n","        self.units = units\n","        assert kernel_size in [1, 3, 5], \"kernel of this size not supported\"\n","        self.kernel_size = kernel_size\n","        if self.kernel_size == 1:\n","            self.stack = lambda x: x\n","        elif self.kernel_size == 3:\n","            self.stack = self.stack3x3\n","        elif self.kernel_size == 5:\n","            self.stack = self.stack5x5\n","        self.stride = stride\n","        if padding == 'same':\n","            self.pad = self.kernel_size // 2\n","            self.pad_1 = 1\n","            self.clip = 0\n","        elif padding == 'valid':\n","            self.pad = 0\n","            self.pad_1 = 0\n","            self.clip = self.kernel_size // 2\n","\n","    def build(self, input_shape):\n","        self.in_shape = input_shape\n","        self.out_y = math.ceil((self.in_shape[1] - 2 * self.clip) / self.stride)\n","        self.out_x = math.ceil((self.in_shape[2] - 2 * self.clip) / self.stride)\n","        self.flat_size = self.out_x * self.out_y\n","        self.channels = self.in_shape[3]\n","        self.w = self.add_weight(\n","            shape=(1, self.channels * tf.square(self.kernel_size), self.units),\n","            initializer=\"glorot_uniform\", name='w',\n","            trainable=True,\n","        )\n","        p_init = tf.constant_initializer(value=100**0.5)\n","        self.p = self.add_weight(\n","            shape=(self.units,), initializer=p_init, trainable=True, name='p')\n","\n","        q_init = tf.constant_initializer(value=10**0.5)\n","        self.q = self.add_weight(\n","            shape=(1,), initializer=q_init, trainable=True, name='q')\n","\n","    def l2_normal(self, x, axis=None, epsilon=1e-12):\n","        square_sum = tf.reduce_sum(tf.square(x), axis, keepdims=True)\n","        x_inv_norm = tf.sqrt(tf.maximum(square_sum, epsilon))\n","        return x_inv_norm\n","\n","    def stack3x3(self, image):\n","        '''\n","            sliding window implementation for 3x3 kernel\n","        '''\n","        x = tf.shape(image)[2]\n","        y = tf.shape(image)[1]\n","        stack = tf.stack(\n","            [\n","                tf.pad(  # top row\n","                    image[:, :y - 1 - self.clip:, :x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, :y - 1 - self.clip, self.clip:x - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [0, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, :y - 1 - self.clip, 1 + self.clip:, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","\n","                tf.pad(  # middle row\n","                    image[:, self.clip:y - self.clip, :x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [0, 0], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                image[:, self.clip:y - self.clip:self.stride, self.clip:x - self.clip:self.stride, :],\n","                tf.pad(\n","                    image[:, self.clip:y - self.clip, 1 + self.clip:, :],\n","                    tf.constant([[0, 0], [0, 0], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","\n","                tf.pad(  # bottom row\n","                    image[:, 1 + self.clip:, :x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [0, self.pad], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1 + self.clip:, self.clip:x - self.clip, :],\n","                    tf.constant([[0, 0], [0, self.pad], [0, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1 + self.clip:, 1 + self.clip:, :],\n","                    tf.constant([[0, 0], [0, self.pad], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :]\n","            ], axis=3)\n","        return stack\n","\n","    def stack5x5(self, image):\n","        '''\n","            sliding window implementation for 5x5 kernel\n","        '''\n","        x = tf.shape(image)[2]\n","        y = tf.shape(image)[1]\n","        stack = tf.stack(\n","            [\n","                tf.pad(  # top row\n","                    image[:, :y - 2 - self.clip:, :x - 2 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, :y - 2 - self.clip:, 1:x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, :y - 2 - self.clip:, self.clip:x - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [0, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, :y - 2 - self.clip:, 1 + self.clip:-1, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, :y - 2 - self.clip:, 2 + self.clip:, :],\n","                    tf.constant([[0, 0], [self.pad, 0], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","\n","                tf.pad(  # 2nd row\n","                    image[:, 1:y - 1 - self.clip:, :x - 2 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1:y - 1 - self.clip:, 1:x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1:y - 1 - self.clip:, self.clip:x - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [0, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1:y - 1 - self.clip:, 1 + self.clip:-1, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1:y - 1 - self.clip:, 2 + self.clip:, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","\n","                tf.pad(  # 3rd row\n","                    image[:, self.clip:y - self.clip, :x - 2 - self.clip, :],\n","                    tf.constant([[0, 0], [0, 0], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, self.clip:y - self.clip, 1:x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [0, 0], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                image[:, self.clip:y - self.clip, self.clip:x - self.clip, :][:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, self.clip:y - self.clip, 1 + self.clip:-1, :],\n","                    tf.constant([[0, 0], [0, 0], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, self.clip:y - self.clip, 2 + self.clip:, :],\n","                    tf.constant([[0, 0], [0, 0], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","\n","                tf.pad(  # 4th row\n","                    image[:, 1 + self.clip:-1, :x - 2 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1 + self.clip:-1, 1:x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1 + self.clip:-1, self.clip:x - self.clip, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [0, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1 + self.clip:-1, 1 + self.clip:-1, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 1 + self.clip:-1, 2 + self.clip:, :],\n","                    tf.constant([[0, 0], [self.pad_1, self.pad_1], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","\n","                tf.pad(  # 5th row\n","                    image[:, 2 + self.clip:, :x - 2 - self.clip, :],\n","                    tf.constant([[0, 0], [0, self.pad], [self.pad, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 2 + self.clip:, 1:x - 1 - self.clip, :],\n","                    tf.constant([[0, 0], [0, self.pad], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 2 + self.clip:, self.clip:x - self.clip, :],\n","                    tf.constant([[0, 0], [0, self.pad], [0, 0], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 2 + self.clip:, 1 + self.clip:-1, :],\n","                    tf.constant([[0, 0], [0, self.pad], [self.pad_1, self.pad_1], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","                tf.pad(\n","                    image[:, 2 + self.clip:, 2 + self.clip:, :],\n","                    tf.constant([[0, 0], [0, self.pad], [0, self.pad], [0, 0]])\n","                )[:, ::self.stride, ::self.stride, :],\n","            ], axis=3)\n","        return stack\n","\n","    @tf.function\n","    def call(self, inputs, training=None):\n","        channels = tf.shape(inputs)[-1]\n","        x = self.stack(inputs)\n","        x = tf.reshape(x, (-1, self.flat_size, channels * tf.square(self.kernel_size)))\n","        x_norm = (self.l2_normal(x, axis=2) + tf.square(self.q)/10)\n","        w_norm = (self.l2_normal(self.w, axis=1) + tf.square(self.q)/10)\n","        x = tf.matmul(x / x_norm, self.w / w_norm)\n","        sign = tf.sign(x)\n","        x = tf.abs(x) + 1e-12\n","        x = tf.pow(x, tf.square(self.p)/100)\n","        x = sign * x\n","        x = tf.reshape(x, (-1, self.out_y, self.out_x, self.units))\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MODEL = \"SCS\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-14T09:18:47.580531Z","iopub.status.busy":"2022-02-14T09:18:47.580241Z","iopub.status.idle":"2022-02-14T09:18:47.714488Z","shell.execute_reply":"2022-02-14T09:18:47.71374Z","shell.execute_reply.started":"2022-02-14T09:18:47.580501Z"},"trusted":true},"outputs":[],"source":["if MODEL == \"SCS\":\n","    model = Sequential([\n","        InputLayer((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS), name=\"input\"),\n","        #\n","        Rescaling(1.0/255.0, name=\"layer00\"),\n","        #\n","        CosSim2D(KERNEL, FILTERS*1, padding=\"same\"),\n","        MaxAbsPool2D(STRIDES, True),\n","        # Dropout(DROPOUT, name=\"layer04\"),\n","        #\n","        CosSim2D(KERNEL, FILTERS*2, padding=\"same\"),\n","        MaxAbsPool2D(STRIDES, True),\n","        # Dropout(DROPOUT, name=\"layer08\"),\n","        #\n","        CosSim2D(KERNEL, FILTERS*2, padding=\"same\"),\n","        MaxAbsPool2D(STRIDES, True),\n","        # Dropout(DROPOUT, name=\"layer12\"),\n","        #\n","        CosSim2D(KERNEL, FILTERS*2, padding=\"same\"),\n","        MaxAbsPool2D(STRIDES, True),\n","        # Dropout(DROPOUT, name=\"layer13\"),\n","        #\n","        CosSim2D(KERNEL, FILTERS*4, padding=\"same\"),\n","        MaxAbsPool2D(STRIDES, True),\n","        #\n","        Flatten(name=\"layer16\"),\n","        Dense(DENSE, name=\"layer17\"),\n","        Activation(ACTIVATION, name=\"layer18\"),\n","        Dense(CLASSES, name=\"layer19\"),\n","        Activation(\"softmax\", name=\"layer20\")\n","    ], name=\"ASL\")\n","else:\n","    model = Sequential([\n","        InputLayer((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS), name=\"input\"),\n","        #\n","        Rescaling(1.0/255.0, name=\"layer00\"),\n","        #\n","        Conv2D(FILTERS*1, KERNEL, padding=\"same\", name=\"layer01\"),\n","        Activation(ACTIVATION, name=\"layer02\"),\n","        MaxPool2D(strides=STRIDES, name=\"layer03\"),\n","        # Dropout(DROPOUT, name=\"layer04\"),\n","        #\n","        Conv2D(FILTERS*2, KERNEL, padding=\"same\", name=\"layer05\"),\n","        Activation(ACTIVATION, name=\"layer06\"),\n","        MaxPool2D(strides=STRIDES, name=\"layer07\"),\n","        # Dropout(DROPOUT, name=\"layer08\"),\n","        #\n","        Conv2D(FILTERS*2, KERNEL, padding=\"same\", name=\"layer09\"),\n","        Activation(ACTIVATION, name=\"layer10\"),\n","        MaxPool2D(strides=STRIDES, name=\"layer11\"),\n","        # Dropout(DROPOUT, name=\"layer12\"),\n","        #\n","        Conv2D(FILTERS*2, KERNEL, padding=\"same\", name=\"layer09a\"),\n","        Activation(ACTIVATION, name=\"layer10a\"),\n","        MaxPool2D(strides=STRIDES, name=\"layer11a\"),\n","        # Dropout(DROPOUT, name=\"layer12\"),\n","        #\n","        Conv2D(FILTERS*4, KERNEL, padding=\"same\", name=\"layer13\"),\n","        Activation(ACTIVATION, name=\"layer14\"),\n","        MaxPool2D(strides=STRIDES, name=\"layer15\"),\n","        #\n","        Flatten(name=\"layer16\"),\n","        Dense(DENSE, name=\"layer17\"),\n","        Activation(ACTIVATION, name=\"layer18\"),\n","        Dense(CLASSES, name=\"layer19\"),\n","        Activation(\"softmax\", name=\"layer20\")\n","    ], name=\"ASL\")\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-14T09:03:30.497847Z","iopub.status.busy":"2022-02-14T09:03:30.497556Z","iopub.status.idle":"2022-02-14T09:03:30.508586Z","shell.execute_reply":"2022-02-14T09:03:30.50791Z","shell.execute_reply.started":"2022-02-14T09:03:30.497813Z"},"trusted":true},"outputs":[],"source":["optimizer = Adam(learning_rate=LEARNING_RATE)\n","loss = \"categorical_crossentropy\"\n","model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EPOCHS = 10\n","VERBOSE = 1\n","callbacks = [\n","    LambdaCallback(\n","        on_epoch_end=lambda batch, logs: time.sleep(15),\n","    )\n","]\n","history = model.fit(xyt, validation_data=xyv, epochs=EPOCHS, callbacks=callbacks, verbose=VERBOSE)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","x, y = next(xyp)\n","p = model.predict(x, verbose=1)\n","p_labels = list(xyp.class_indices.keys())\n","p_labels = [\"Label: \" + p_labels[c] for c in np.argmax(p[0:16], axis=-1)]\n","fig = create_image_subplots(x[:16], labels=p_labels, width=720, height=800)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["p = model.predict(xyp, verbose=1)\n","report = metrics.classification_report(\n","    xyp.classes,\n","    np.argmax(p, axis=-1),\n","    target_names=list(xyp.class_indices.keys())\n",")\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.express as px\n","\n","def plot_confusion_matrix(confusion_matrix, labels):\n","    fig = go.Figure()\n","    fig.add_trace(\n","        go.Heatmap(\n","            z = confusion_matrix,\n","            x = labels,\n","            y = labels,\n","        )\n","    )\n","    return fig"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cm = metrics.confusion_matrix(xyp.classes, np.argmax(p, axis=-1))\n","fig = plot_confusion_matrix(cm, list(xyp.class_indices.keys()))\n","fig.update_layout(width=800, height=800)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras import backend as K\n","print(model.optimizer.learning_rate.numpy())\n","K.set_value(model.optimizer.learning_rate, 0.0001)\n","print(model.optimizer.learning_rate.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":4}
